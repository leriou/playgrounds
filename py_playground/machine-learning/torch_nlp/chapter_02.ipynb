{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 248.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-10-11T13:49:15.171437</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.0, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 372.103125 248.518125 \nL 372.103125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \nL 364.903125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m046bfbc53c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"75.75767\" xlink:href=\"#m046bfbc53c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −4 -->\n      <g transform=\"translate(68.386577 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"136.630398\" xlink:href=\"#m046bfbc53c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- −2 -->\n      <g transform=\"translate(129.259304 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"197.503125\" xlink:href=\"#m046bfbc53c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0 -->\n      <g transform=\"translate(194.321875 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"258.375852\" xlink:href=\"#m046bfbc53c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2 -->\n      <g transform=\"translate(255.194602 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"319.24858\" xlink:href=\"#m046bfbc53c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 4 -->\n      <g transform=\"translate(316.06733 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m0ed4bdce7b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0ed4bdce7b\" y=\"216.097307\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.0 -->\n      <g transform=\"translate(7.2 219.896526)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0ed4bdce7b\" y=\"176.026385\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.2 -->\n      <g transform=\"translate(7.2 179.825604)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0ed4bdce7b\" y=\"135.955463\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 139.754682)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0ed4bdce7b\" y=\"95.884541\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 99.68376)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0ed4bdce7b\" y=\"55.81362\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.8 -->\n      <g transform=\"translate(7.2 59.612838)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0ed4bdce7b\" y=\"15.742698\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 19.541916)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_12\">\n    <path clip-path=\"url(#pa9567fbad1)\" d=\"M 45.321307 214.756364 \nL 48.36494 214.616378 \nL 51.408574 214.461899 \nL 54.452222 214.291451 \nL 57.495855 214.103418 \nL 60.539489 213.896023 \nL 63.583122 213.667319 \nL 66.626756 213.415177 \nL 69.670404 213.137261 \nL 72.714037 212.831026 \nL 75.75767 212.493687 \nL 78.801304 212.122211 \nL 81.844945 211.713294 \nL 84.888578 211.263348 \nL 87.932219 210.768477 \nL 90.975852 210.224467 \nL 94.019486 209.626763 \nL 97.063126 208.970455 \nL 100.10676 208.250275 \nL 103.150401 207.460569 \nL 106.194034 206.595315 \nL 109.237668 205.648101 \nL 112.281308 204.612145 \nL 115.324942 203.480305 \nL 118.368582 202.245104 \nL 121.412216 200.898772 \nL 124.455849 199.433275 \nL 127.49949 197.840402 \nL 130.543124 196.111838 \nL 133.586764 194.239254 \nL 136.630398 192.214453 \nL 139.674035 190.029474 \nL 142.717672 187.676792 \nL 145.761305 185.149481 \nL 148.804942 182.441417 \nL 151.84858 179.547512 \nL 154.892217 176.463939 \nL 157.935854 173.188356 \nL 160.979487 169.72018 \nL 164.023124 166.06077 \nL 167.066761 162.213652 \nL 170.110398 158.184709 \nL 173.154034 153.982267 \nL 176.197671 149.617197 \nL 179.241306 145.102911 \nL 182.284943 140.455292 \nL 185.328579 135.692528 \nL 188.372216 130.834902 \nL 191.415852 125.904471 \nL 194.459489 120.924701 \nL 197.503125 115.920002 \nL 200.546761 110.91531 \nL 203.590398 105.93554 \nL 206.634034 101.005103 \nL 209.677671 96.147477 \nL 212.721307 91.384707 \nL 215.764944 86.737094 \nL 218.808579 82.222814 \nL 221.852216 77.857738 \nL 224.895852 73.655302 \nL 227.939489 69.626347 \nL 230.983126 65.779235 \nL 234.026763 62.119816 \nL 237.070396 58.651637 \nL 240.114033 55.37606 \nL 243.15767 52.292499 \nL 246.201308 49.39859 \nL 249.244945 46.690512 \nL 252.288578 44.163225 \nL 255.332215 41.810519 \nL 258.375852 39.625562 \nL 261.419486 37.600749 \nL 264.463126 35.728162 \nL 267.50676 33.999596 \nL 270.550401 32.406727 \nL 273.594034 30.941233 \nL 276.637668 29.594896 \nL 279.681308 28.359705 \nL 282.724942 27.22786 \nL 285.768582 26.191897 \nL 288.812216 25.244689 \nL 291.855849 24.379438 \nL 294.89949 23.589733 \nL 297.943124 22.869543 \nL 300.986764 22.213231 \nL 304.030398 21.615543 \nL 307.074031 21.071534 \nL 310.117672 20.576655 \nL 313.161305 20.126725 \nL 316.204946 19.717781 \nL 319.24858 19.346323 \nL 322.292213 19.008984 \nL 325.335846 18.702742 \nL 328.379494 18.424826 \nL 331.423128 18.172693 \nL 334.466761 17.943979 \nL 337.510395 17.736593 \nL 340.554028 17.548565 \nL 343.597676 17.378104 \nL 346.64131 17.223621 \nL 349.684943 17.083636 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 224.64 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 224.64 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pa9567fbad1\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "x = torch.range(-5., 5., 0.1) \n",
    "y = torch.sigmoid(x) \n",
    "plt.plot(x.numpy(), y.numpy()) \n",
    "plt.show()\n"
   ]
  },
  {
   "source": [
    "# TF-IDF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "bag of words（BOW） 词袋模型\n[[0 1 1 1 0 0 1 0 1]\n [0 1 0 1 0 2 1 0 1]\n [1 0 0 0 1 0 1 1 0]\n [0 1 1 1 0 0 1 0 1]]\n\n ------------------------------ \n\nTF-IDF 模型\n[[0.         0.43877674 0.54197657 0.43877674 0.         0.\n  0.35872874 0.         0.43877674]\n [0.         0.27230147 0.         0.27230147 0.         0.85322574\n  0.22262429 0.         0.27230147]\n [0.55280532 0.         0.         0.         0.55280532 0.\n  0.28847675 0.55280532 0.        ]\n [0.         0.43877674 0.54197657 0.43877674 0.         0.\n  0.35872874 0.         0.43877674]]\n\n ------------------------------ \n\nTF-IDF 模型\n[[0.         0.43877674 0.54197657 0.43877674 0.         0.\n  0.35872874 0.         0.43877674]\n [0.         0.27230147 0.         0.27230147 0.         0.85322574\n  0.22262429 0.         0.27230147]\n [0.55280532 0.         0.         0.         0.55280532 0.\n  0.28847675 0.55280532 0.        ]\n [0.         0.43877674 0.54197657 0.43877674 0.         0.\n  0.35872874 0.         0.43877674]]\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "TF-IDF 模型：\n",
    "主要思想是，如果某个词或短语在一篇文章中出现的频率TF(Term Frequency，词频)，词频高，\n",
    "    并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。\n",
    "公式：\n",
    "* TF-IDF = TF * IDF\n",
    "* TF(t) = (词t在文档中出现的总次数) / (文档的词总数)\n",
    "* IDF = log_e(总文档数/词t出现的文档数)\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 语料\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "计算方式1: 通过手动的进行计算词频\n",
    "\"\"\"\n",
    "# 将文本中的词语转换为词频矩阵\n",
    "cv = CountVectorizer(min_df=1)\n",
    "# 计算个词语出现的次数\n",
    "cv_fit = cv.fit_transform(corpus)\n",
    "print(\"bag of words（BOW） 词袋模型\")\n",
    "print(cv_fit.toarray())\n",
    "\n",
    "print(\"\\n\", \"---\" * 10, \"\\n\")\n",
    "\n",
    "# 计算 IF-IDF的值\n",
    "transformer = TfidfTransformer()\n",
    "# 将词频矩阵 cv_fit 统计成 TF-IDF 值\n",
    "tfidf = transformer.fit_transform(cv_fit)\n",
    "# 查看数据结构 tfidf[i][j] 表示i类文本中 tf-idf 权重\n",
    "print(\"TF-IDF 模型\")\n",
    "print(tfidf.toarray())\n",
    "\n",
    "\n",
    "print(\"\\n\", \"---\" * 10, \"\\n\")\n",
    "\"\"\"\n",
    "计算方式2: 直接通过 文本词料 来计算文本中 tf-idf 权重\n",
    "\"\"\"\n",
    "# 计算 IF-IDF的值\n",
    "transformer = TfidfVectorizer()\n",
    "# 将词频矩阵 cv 统计成 TF-IDF 值\n",
    "tfidf = transformer.fit_transform(corpus)\n",
    "# 查看数据结构 tfidf[i][j] 表示i类文本中的 tf-idf 权重\n",
    "print(\"TF-IDF 模型\")\n",
    "print(tfidf.toarray())"
   ]
  },
  {
   "source": [
    "# Count Word2Vec"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "打印所有的特征名称\n['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n打印整个文本矩阵\n[[0 1 1 1 0 0 1 0 1]\n [0 1 0 1 0 2 1 0 1]\n [1 0 0 0 1 0 1 1 0]\n [0 1 1 1 0 0 1 0 1]]\n打印所有的列相加\n[1 3 2 3 1 2 4 1 3]\n打印所有的行相加\n[5 6 4 5]\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "词集模型：单词构成的集合，集合自然每个元素都只有一个，也即词集中的每个单词都只有一个\n",
    "词袋模型：在词集的基础上如果一个单词在文档中出现不止一次，统计其出现的次数（频数）\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 语料\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "\n",
    "# 将文本中的词语转换为词频矩阵\n",
    "cv = CountVectorizer(min_df=1)\n",
    "# 计算个词语出现的次数\n",
    "cv_fit = cv.fit_transform(corpus)\n",
    "\n",
    "# set of words（SOW） 词集模型 - 获取词袋中所有文本关键词\n",
    "print(\"打印所有的特征名称\")\n",
    "print(cv.get_feature_names())\n",
    "\n",
    "# bag of words（BOW） 词袋模型\n",
    "print(\"打印整个文本矩阵\")\n",
    "print(cv_fit.toarray())\n",
    "print(\"打印所有的列相加\")\n",
    "print(cv_fit.toarray().sum(axis=0))\n",
    "print(\"打印所有的行相加\")\n",
    "print(cv_fit.toarray().sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "打印词汇表: \n",
      " {'me': 0, 'gusta': 1, 'comer': 2, 'en': 3, 'la': 4, 'cafeteria': 5, 'Give': 6, 'it': 7, 'to': 8, 'No': 9, 'creo': 10, 'que': 11, 'sea': 12, 'una': 13, 'buena': 14, 'idea': 15, 'is': 16, 'not': 17, 'a': 18, 'good': 19, 'get': 20, 'lost': 21, 'at': 22, 'Yo': 23, 'si': 24, 'on': 25}\n",
      "bow_vector: \n",
      " tensor([[1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[-0.8195, -0.5810]], grad_fn=<LogSoftmaxBackward>)\n",
      "训练后 ---: \n",
      " tensor([[-0.1210, -2.1721]], grad_fn=<LogSoftmaxBackward>)\n",
      "训练后 ---: \n",
      " tensor([[-2.7767, -0.0643]], grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([ 0.5004, -0.2738], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "\n",
    "data = [(\"me gusta comer en la cafeteria\".split(), \"SPANISH\"),\n",
    "        (\"Give it to me\".split(), \"ENGLISH\"),\n",
    "        (\"No creo que sea una buena idea\".split(), \"SPANISH\"),\n",
    "        (\"No it is not a good idea to get lost at sea\".split(), \"ENGLISH\")]\n",
    "\n",
    "test_data = [(\"Yo creo que si\".split(), \"SPANISH\"),\n",
    "             (\"it is lost on me\".split(), \"ENGLISH\")]\n",
    "\n",
    "label_to_ix = {\"SPANISH\": 0, \"ENGLISH\": 1}\n",
    "\n",
    "\n",
    "# word_to_ix 将词汇表中的每个单词映射到一个唯一的整数，这将成为单词向量袋中的索引\n",
    "word_to_ix = {}\n",
    "for sent, _ in data + test_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print(\"打印词汇表: \\n\", word_to_ix)\n",
    "\n",
    "# 输入的特征数\n",
    "VOCAB_SIZE = len(word_to_ix)\n",
    "# 输出的结果\n",
    "NUM_LABELS = 2\n",
    "\n",
    "\n",
    "# 继承 nn.Module\n",
    "class BoWClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        # 调用 nn.Module 的 init 函数。 不要被语法混淆，只是总是在 nn.Module 中做\n",
    "        super(BoWClassifier, self).__init__()\n",
    "\n",
    "        # 定义您将需要的参数。\n",
    "        # 在这种情况下，我们需要A和b，仿射映射的参数。\n",
    "        # Torch定义了nn.Linear()，它提供了仿射图。\n",
    "        # 确保你明白为什么输入维度是 vocab_size，输出是 num_labels！\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "\n",
    "        # NOTE! 非线性日志softmax没有参数！ 所以我们不需要为此担心\n",
    "\n",
    "    def forward(self, bow_vec):\n",
    "        # 通过线性层传递输入，\n",
    "        # 然后通过 log_softmax 传递。（使用对数形式的 softmax 函数）\n",
    "        # 许多非线性和其他功能在 torch.nn.functional 中\n",
    "        # SVM只选自己喜欢的男神，Softmax把所有备胎全部拉出来评分，最后还归一化一下\n",
    "        return F.log_softmax(self.linear(bow_vec), dim=1)\n",
    "\n",
    "\n",
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for word in sentence:\n",
    "        vec[word_to_ix[word]] += 1\n",
    "    # 返回一个有相同数据但大小不同的新的 tensor.（ -1表示其他维度 ）\n",
    "    \"\"\"\n",
    "    # -1 表示自己不确定，让系统来计算\n",
    "    y = x.view(4, 2)\n",
    "    print y\n",
    "    # 输出如下\n",
    "    1.5600 -1.6180\n",
    "    -2.0366  2.7115\n",
    "    0.8415 -1.0103\n",
    "    -0.4793  1.5734\n",
    "    [torch.FloatTensor of size 4x2]\n",
    "    \"\"\"\n",
    "    return vec.view(1, -1)\n",
    "\n",
    "\n",
    "def make_target(label, label_to_ix):\n",
    "    return torch.LongTensor([label_to_ix[label]])\n",
    "\n",
    "\n",
    "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\n",
    "\n",
    "# 模型知道它的参数。 下面的第一个输出是A，第二个输出是b。\n",
    "# 只要你在一个模块的 __init__ 函数中将一个组件分配给一个类变量，这是通过该行完成的\n",
    "# self.linear = nn.Linear（...）\n",
    "# 然后通过 Pytorch 开发者的一些 Python 魔法，你的模块（在这种情况下，BoWClassifier）将存储关于 nn.Linear 参数的知识\n",
    "# for param in model.parameters():\n",
    "#     print(\"\\n parameters 参数有: \\n\", param)\n",
    "\n",
    "# 要运行该模型，传入一个BoW variable，但包裹在一个 autograd.Variable 中\n",
    "sample = data[0]\n",
    "# 将文本转化为 Variable 对象\n",
    "bow_vector = make_bow_vector(sample[0], word_to_ix)\n",
    "print(\"bow_vector: \\n\", bow_vector)\n",
    "log_probs = model(autograd.Variable(bow_vector))\n",
    "# 将原始数据从 x ⇒ log (x)，无疑会将原始数据的值域进行一定的收缩。\n",
    "\"\"\"lable目标变量的：最终的分类下所有结果的概率（下面为: SPANISH 和 ENGLISH 的概率分布-暂时还没有定义先后顺序，默认是字母？）\n",
    "Variable containing:\n",
    "-0.8195 -0.5810\n",
    "\"\"\"\n",
    "print(log_probs)\n",
    "\n",
    "\n",
    "# # 在我们训练之前运行测试数据，只是为了看到前后的变化\n",
    "# for instance, label in test_data:\n",
    "#     bow_vec = autograd.Variable(make_bow_vector(instance, word_to_ix))\n",
    "#     log_probs = model(bow_vec)\n",
    "#     print(\"训练前 ---: \\n\", log_probs)\n",
    "\n",
    "# # 打印对应于 \"creo\" 的矩阵列的计算值，用于对比训练后的结果变化\n",
    "# print('model.parameters(): \\n', next(model.parameters())[:, word_to_ix[\"creo\"]])\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "# 通常你想多次传递训练数据。\n",
    "# 100比实际的数据集大得多，但真正的数据集不止\n",
    "# 两个实例。通常，5至30个时期是合理的。\n",
    "for epoch in range(100):\n",
    "    for instance, label in data:\n",
    "        # 步骤1.\n",
    "        # 请记住，Pytorch会累积渐变。\n",
    "        # 我们需要在每个实例之前清除它们\n",
    "        model.zero_grad()\n",
    "\n",
    "        # 第2步.\n",
    "        # 制作我们的BOW矢量，并且我们还必须将目标包装在一个\n",
    "        # 作为整数变量\n",
    "        # 例如: 如果目标是西班牙语，那么我们包装整数0.\n",
    "        # 然后，损失函数知道日志概率的第0个元素是对应于西班牙语的日志概率\n",
    "        bow_vec = autograd.Variable(make_bow_vector(instance, word_to_ix))\n",
    "        target = autograd.Variable(make_target(label, label_to_ix))\n",
    "\n",
    "        # 第3步.\n",
    "        # 开始训练模型\n",
    "        log_probs = model(bow_vec)\n",
    "\n",
    "        # 第4步.\n",
    "        # 通过调用optimizer.step（）来计算损失，梯度和更新参数\n",
    "        loss = loss_function(log_probs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "for instance, label in test_data:\n",
    "    bow_vec = autograd.Variable(make_bow_vector(instance, word_to_ix))\n",
    "    log_probs = model(bow_vec)\n",
    "    print(\"训练后 ---: \\n\", log_probs)\n",
    "\n",
    "# Index corresponding to Spanish goes up, English goes down!\n",
    "print(next(model.parameters())[:, word_to_ix[\"creo\"]])"
   ]
  }
 ]
}