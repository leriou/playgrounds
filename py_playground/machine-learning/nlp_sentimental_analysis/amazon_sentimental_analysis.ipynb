{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# amazon 评论的情感识别\n",
    "使用amazon的评论信息进行情感识别，目的是为了测试算法的识别准确度\n",
    "\n",
    "因为我们当前的训练数据不靠谱所以拿amazon的评论数据来做算法效果验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "指定文件数据路径\n",
    "\"\"\"\n",
    "train_data_path = \"../../datasets/amazon.csv\"\n",
    "stop_words_path = \"../../datasets/stop_words.txt\"\n",
    "bayes_model_path = \"../models/amazon_native_bayes.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先处理数据，分词，停用词等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "data = pd.read_csv(train_data_path)\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data[\"reviewText\"]\n",
    "y = data[\"Positive\"]\n",
    "# 切分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_custom_stopwords(stop_words_file):\n",
    "    with open(stop_words_file) as f:\n",
    "        stopwords = f.read()\n",
    "    stopwords_list = stopwords.split('\\n')\n",
    "    custom_stopwords_list = [i for i in stopwords_list]\n",
    "    return custom_stopwords_list\n",
    "\n",
    "# 加载停用词\n",
    "stopwords = get_custom_stopwords(stop_words_path)\n",
    "\n",
    "# print(stopwords)\n",
    "# 次数统计向量\n",
    "vect = CountVectorizer(max_df = 0.8, \n",
    "                       min_df = 2, \n",
    "                       token_pattern=u'(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b', \n",
    "                       stop_words=frozenset(stopwords))\n",
    "# tf向量化，效果较差\n",
    "# vect = TfidfVectorizer()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame(vect.fit_transform(X_train).toarray(), columns=vect.get_feature_names())\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Gensim生成的词向量处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "size = 50\n",
    "class MyCorpus(object):\n",
    "    def __iter__(self):\n",
    "        for line in data[\"reviewText\"]:\n",
    "            yield utils.simple_preprocess(line)\n",
    "\n",
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences,sg=1,size=size,\n",
    "window=5,min_count=1,\n",
    "negative=3,sample=0.001,\n",
    "hs=1,workers=4)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据词向量生成句向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sentence2vec(content):\n",
    "    tmp = np.zeros(size)\n",
    "    for w in content.split(\" \"):\n",
    "        if w in model.wv:\n",
    "            tmp += model.wv[w]\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用贝叶斯模型来处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = vect.fit_transform(X_train)\n",
    "X_test_vect = vect.transform(X_test)\n",
    "\"\"\"\n",
    "使用gensim生成句向量\n",
    "\"\"\"\n",
    "# X_train_vect = [[n for n in sentence2vec(i)] for i in X_train]\n",
    "# X_test_vect = [[n for n in sentence2vec(i)] for i in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vect, y_train)\n",
    "train_score = nb.score(X_test_vect, y_test)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络来处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(max_iter=2)\n",
    "mlp.fit(X_train_vect, y_train)\n",
    "train_score = mlp.score(X_test_vect, y_test)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_vect, y_train)\n",
    "train_score = lr.score(X_test_vect, y_test)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save model to disk and reload model from disk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(mlp, open(bayes_model_path,\"wb\"))\n",
    "# pickle.dump(nb, open(bayes_model_path,\"wb\"))\n",
    "\n",
    "model_2 = pickle.load(open(bayes_model_path, \"rb\"))\n",
    "print(model_2.score(X_train_vect, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找一条具体内容测试一下, 具体输出是0 ，说明预测还是比较准确的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_text = \"Loved this alarm clock till it started forceclosing everyday. It works one time, then the next time you try to use it, it tells you to download it again from them Amazon app store.  Uninstall and reinstall and it works once and FC again. Vibrant tooted \"\n",
    "\n",
    "res = vect.transform([new_text])\n",
    "print(model_2.predict(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将结果合并到原来的数据中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_vec = vect.transform(X)\n",
    "nb_result = nb.predict(X_vec)\n",
    "data['nb_result'] = nb_result\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext classification \n",
    "\n",
    "1. 格式转换工具将普通的csv训练数据文件变为共fasttext使用的训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import fasttext\n",
    "import random\n",
    "\n",
    "amazon_source = \"..../datasets/amazon.csv\"\n",
    "\n",
    "def trans_file(old_file):\n",
    "    x = old_file + \".train\"\n",
    "    y = old_file + \".valid\"\n",
    "    h = pd.read_csv(old_file)\n",
    "\n",
    "    with open(x, \"w+\") as fx:\n",
    "        with open(y, \"w+\") as fy:\n",
    "            for i in range(0, len(h)):\n",
    "                s = \"__label__\" + str(h['Positive'][i])+\" \" + h['reviewText'][i] + \"\\n\"\n",
    "                if i > 17000:\n",
    "                    fy.write(s)\n",
    "                else:\n",
    "                    fx.write(s)\n",
    "    return x,y\n",
    "\n",
    "amazon_train, amazon_test = trans_file(amazon_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=amazon_train,epoch=10,lr=1.0,wordNgrams=2,dim=100,loss='hs')\n",
    "model.test(amazon_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(\"got this kindle fire for Christmas. trying to download free angry birds and it is not working. started to down load over 2 hours ago. an it is only at 2 percent still. piece of crap:(\",k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
